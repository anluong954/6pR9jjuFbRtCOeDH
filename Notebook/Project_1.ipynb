{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-28T02:18:19.367833Z",
     "start_time": "2025-07-28T02:18:15.652799Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1KWE3J0uU_sFIJnZ74Id3FDBcejELI7FD\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers\n",
    "# X1 = my order was delivered on time\n",
    "# X2 = contents of my order was as I expected\n",
    "# X3 = I ordered everything I wanted to order\n",
    "# X4 = I paid a good price for my order\n",
    "# X5 = I am satisfied with my courier\n",
    "# X6 = the app makes ordering easy for me\n",
    "\n",
    "# Pre-process Data\n",
    "x = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]\n",
    "y = df['Y']\n",
    "# splitting data original\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# decision tree, K nearest, X boost\n",
    "# correlation feature selection\n",
    "\n",
    "# Random Forest Classifier model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# feature selection\n",
    "rf_selector = RFE(estimator=rf_model, n_features_to_select=3)\n",
    "# fit RFE\n",
    "rf_selected = rf_selector.fit_transform(x, y)\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(rf_selected, y, test_size = 0.15, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest Model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_f1_score = f1_score(y_test, rf_y_pred)\n",
    "print(\"Random Forest Classifier Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {rf_f1_score:.4f}\")\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "# feature selection\n",
    "dt_selector = RFE(estimator=dt_model, n_features_to_select=3)\n",
    "# fit RFE\n",
    "dt_selected = dt_selector.fit_transform(x, y)\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(dt_selected, y, test_size = 0.15, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "dt_f1_score = f1_score(y_test, dt_y_pred)\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {dt_f1_score:.4f}\")\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "\n",
    "# K-Nearest Neighbors Classifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state=42)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "knn_f1_score = f1_score(y_test, knn_y_pred)\n",
    "print(\"K-Nearest Neighbors Results:\")\n",
    "print(f\"Accuracy: {knn_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {knn_f1_score:.4f}\")\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, knn_y_pred))\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "# feature Selection\n",
    "xg_selector = RFE(estimator=xgb_model, n_features_to_select=3)\n",
    "# fit RFE\n",
    "xg_selected = xg_selector.fit_transform(x, y)\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(xg_selected, y, test_size = 0.15, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "xgb_f1_score = f1_score(y_test, xgb_y_pred)\n",
    "print(\"XGBoost Results:\")\n",
    "print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {xgb_f1_score:.4f}\")\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, xgb_y_pred))\n",
    "\n",
    "# svm\n",
    "svm_model = svm.SVC()\n",
    "# training the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "# Evaluate SVM\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "svm_f1_score = f1_score(y_test, svm_y_pred)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"F1 Score: {svm_f1_score:.4f}\")\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, svm_y_pred))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Y  X1  X2  X3  X4  X5  X6\n",
      "0  0   3   3   3   4   2   4\n",
      "1  0   3   2   3   5   4   3\n",
      "2  1   5   3   3   3   3   5\n",
      "3  0   5   4   3   3   3   5\n",
      "4  0   5   4   3   3   3   5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Y       126 non-null    int64\n",
      " 1   X1      126 non-null    int64\n",
      " 2   X2      126 non-null    int64\n",
      " 3   X3      126 non-null    int64\n",
      " 4   X4      126 non-null    int64\n",
      " 5   X5      126 non-null    int64\n",
      " 6   X6      126 non-null    int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 7.0 KB\n",
      "None\n",
      "Random Forest Classifier Results:\n",
      "Accuracy: 0.7368\n",
      "F1 Score: 0.7368\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        10\n",
      "           1       0.70      0.78      0.74         9\n",
      "\n",
      "    accuracy                           0.74        19\n",
      "   macro avg       0.74      0.74      0.74        19\n",
      "weighted avg       0.74      0.74      0.74        19\n",
      "\n",
      "Decision Tree Results:\n",
      "Accuracy: 0.7895\n",
      "F1 Score: 0.8000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        10\n",
      "           1       0.73      0.89      0.80         9\n",
      "\n",
      "    accuracy                           0.79        19\n",
      "   macro avg       0.80      0.79      0.79        19\n",
      "weighted avg       0.81      0.79      0.79        19\n",
      "\n",
      "K-Nearest Neighbors Results:\n",
      "Accuracy: 0.5263\n",
      "F1 Score: 0.6087\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.30      0.40        10\n",
      "           1       0.50      0.78      0.61         9\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.55      0.54      0.50        19\n",
      "weighted avg       0.55      0.53      0.50        19\n",
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.6842\n",
      "F1 Score: 0.7273\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.50      0.62        10\n",
      "           1       0.62      0.89      0.73         9\n",
      "\n",
      "    accuracy                           0.68        19\n",
      "   macro avg       0.72      0.69      0.68        19\n",
      "weighted avg       0.73      0.68      0.67        19\n",
      "\n",
      "SVM Results:\n",
      "Accuracy: 0.5263\n",
      "F1 Score: 0.6400\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.20      0.31        10\n",
      "           1       0.50      0.89      0.64         9\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.58      0.54      0.47        19\n",
      "weighted avg       0.59      0.53      0.47        19\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "68a03662d0017cdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
