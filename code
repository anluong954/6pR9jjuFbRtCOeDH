from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.feature_selection import RFE
from sklearn.preprocessing import StandardScaler

url = "https://drive.google.com/uc?id=1KWE3J0uU_sFIJnZ74Id3FDBcejELI7FD"
df = pd.read_csv(url)
print(df.info())

# Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers
# X1 = my order was delivered on time
# X2 = contents of my order was as I expected
# X3 = I ordered everything I wanted to order
# X4 = I paid a good price for my order
# X5 = I am satisfied with my courier
# X6 = the app makes ordering easy for me

# Pre-process Data
x = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]
y = df['Y']

# Since accuracy and f1-score looks to be low, want to hyper-parameter tuning
# model
model = RandomForestClassifier(n_estimators=100, random_state=42)
# feature selection
selector = RFE(estimator=model, n_features_to_select=3)
x_selected = selector.fit_transform(x, y)

# split the data
X_train, X_test, y_train, y_test = train_test_split(x_selected, y, test_size = 0.3, random_state=42)

# train model
model.fit(X_train, y_train)

# prediction
y_pred = model.predict(X_test)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
confusion = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

# looking for F1 score (F1 score is the average of precision and recall)
f1_score = f1_score(y_test, y_pred)
print("F1 Score:")
print(f1_score)
print("Results:")
print(f"Accuracy: {accuracy:.4f}")
#print('Confusion Matrix: ')
#print(confusion)
print('Classification Report:')
print(class_report)
